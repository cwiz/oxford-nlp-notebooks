{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from random import shuffle\n",
    "import re\n",
    "from gensim.models import KeyedVectors\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset if it's not already there\n",
    "if not os.path.isfile('ted_en-20160408.zip'):\n",
    "    urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract both the texts and the labels from the xml file\n",
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n",
    "texts = doc.xpath('//content/text()')\n",
    "labels = doc.xpath('//head/keywords/text()')\n",
    "del doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_category(labels):\n",
    "    technology = 'technology' in labels\n",
    "    entertainment = 'entertainment' in labels\n",
    "    design = 'design' in labels\n",
    "    \n",
    "    if technology and entertainment and design:\n",
    "        return \"TED\"\n",
    "    if entertainment and design:\n",
    "        return \"oED\"\n",
    "    if technology and design:\n",
    "        return \"ToD\"\n",
    "    if technology and entertainment:\n",
    "        return \"TEo\"\n",
    "    if entertainment:\n",
    "        return \"oEo\"\n",
    "    if technology:\n",
    "        return \"Too\"\n",
    "    if design:\n",
    "        return \"ooD\"\n",
    "    return \"ooo\"\n",
    "\n",
    "categories = [extract_category(l) for l in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert a corpus into one-hot representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "all_sentences = []\n",
    "\n",
    "for talk in texts:\n",
    "    sentences = talk.split('\\n')\n",
    "    for sentence in sentences:\n",
    "        tokens = re.sub(r\"[^a-z0-9]+\", \" \", sentence.lower()).split()\n",
    "        all_tokens.extend(tokens)\n",
    "        all_sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = {}\n",
    "for token in all_tokens:\n",
    "    if token not in all_words:\n",
    "        all_words[token] = 0\n",
    "    all_words[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "counts_ted_top1000 = [i[1] for i in sorted(list(all_words.items()), key=itemgetter(1))[-1000:]]\n",
    "words_ted_top1000 = [i[0] for i in sorted(list(all_words.items()), key=itemgetter(1))[-1000:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_tokens[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, edges = np.histogram(counts_ted_top1000, density=True, bins=100, normed=True)\n",
    "\n",
    "p = figure(tools=\"pan,wheel_zoom,reset,save\",\n",
    "           toolbar_location=\"above\",\n",
    "           title=\"Top-1000 words distribution\")\n",
    "p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], line_color=\"#555555\")\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "embedding_size = 500\n",
    "\n",
    "model_ted = Word2Vec(all_sentences, size=embedding_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train neural classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define neural model: assignment assumes we will use an embedding to convert from input text to labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using \"bag of means\" method to represent input text.\n",
    "\n",
    "Bag of means representation where X is embedded vector for each word in sentence:\n",
    "\n",
    "**x=sum(X)/len(N)**\n",
    "\n",
    "## Construct dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"TED\", \"oED\", \"ToD\", \"TEo\", \"oEo\", \"Too\", \"ooD\", \"ooo\"]\n",
    "labels_raw = []\n",
    "for c in categories:\n",
    "    l = np.zeros(len(classes))\n",
    "    l[classes.index(c)] = 1\n",
    "    labels_raw.append(l)\n",
    "\n",
    "encoded_talks = []\n",
    "labels = []\n",
    "for index, talk in enumerate(texts):\n",
    "    sentences = talk.split('\\n')\n",
    "    sentence_vector = np.zeros(embedding_size)\n",
    "    num_vectors = 0\n",
    "    for sentence in sentences:\n",
    "        tokens = re.sub(r\"[^a-z0-9]+\", \" \", sentence.lower()).split()\n",
    "        for token in tokens:\n",
    "            if token not in model_ted.wv:\n",
    "                continue\n",
    "            sentence_vector += model_ted.wv[token]\n",
    "            num_vectors += 1\n",
    "    if num_vectors > 0:\n",
    "        encoded_talks.append(sentence_vector/num_vectors)\n",
    "        labels.append(labels_raw[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(encoded_talks[:1700])\n",
    "y_train = np.array(labels[:1700])\n",
    "\n",
    "x_test = np.array(encoded_talks[1700:])\n",
    "y_test = np.array(labels[1700:])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "num_cores = 16\n",
    "\n",
    "CPU = False\n",
    "GPU = True\n",
    "\n",
    "if GPU:\n",
    "    num_GPU = 1\n",
    "    num_CPU = 1\n",
    "if CPU:\n",
    "    num_CPU = 1\n",
    "    num_GPU = 0\n",
    "\n",
    "config = tensorflow.ConfigProto(intra_op_parallelism_threads=num_cores,\\\n",
    "        inter_op_parallelism_threads=num_cores, allow_soft_placement=True,\\\n",
    "        device_count = {'CPU' : num_CPU, 'GPU' : num_GPU})\n",
    "session = tensorflow.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_dim=embedding_size))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1200, batch_size=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x=x_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
